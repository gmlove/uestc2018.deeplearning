{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图像识别问题数据集：\n",
    "<img src=\"images/cnn-dataset.png\" style=\"width:450px;height:300px;\">\n",
    "LeNet 5 模型:\n",
    "<img src=\"images/lenet-5.png\" style=\"width:850px;height:300px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "train images: (55000, 784), train labels: (55000, 10), validation images: (5000, 784), validation labels: (5000, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "print('train images: {}, train labels: {}, validation images: {}, validation labels: {}'.format(\n",
    "  mnist.train.images.shape, mnist.train.labels.shape, mnist.validation.images.shape, mnist.validation.labels.shape\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label is: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122441ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 100\n",
    "plt.imshow(mnist.train.images[idx].reshape(28, 28))\n",
    "print('label is: {}'.format(np.argmax(mnist.train.labels[idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/lj/b2trvfyj0mjbjf90yx92y6d80000gn/T/tmpfplgq5h5\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/lj/b2trvfyj0mjbjf90yx92y6d80000gn/T/tmpfplgq5h5', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x12664c518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/lj/b2trvfyj0mjbjf90yx92y6d80000gn/T/tmpfplgq5h5/keras_model.ckpt\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/lj/b2trvfyj0mjbjf90yx92y6d80000gn/T/tmpfplgq5h5/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.30931, step = 1\n",
      "INFO:tensorflow:global_step/sec: 26.441\n",
      "INFO:tensorflow:loss = 2.2629533, step = 101 (3.783 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.5265\n",
      "INFO:tensorflow:loss = 2.0990543, step = 201 (3.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.6662\n",
      "INFO:tensorflow:loss = 1.0516864, step = 301 (4.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.7021\n",
      "INFO:tensorflow:loss = 0.5247734, step = 401 (3.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5118\n",
      "INFO:tensorflow:loss = 0.42477208, step = 501 (4.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.4312\n",
      "INFO:tensorflow:loss = 0.3901879, step = 601 (4.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.4373\n",
      "INFO:tensorflow:loss = 0.24548489, step = 701 (4.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7112\n",
      "INFO:tensorflow:loss = 0.25481707, step = 801 (4.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0306\n",
      "INFO:tensorflow:loss = 0.37265205, step = 901 (4.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.7232\n",
      "INFO:tensorflow:loss = 0.24708241, step = 1001 (4.825 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1409\n",
      "INFO:tensorflow:loss = 0.13215202, step = 1101 (4.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.5067\n",
      "INFO:tensorflow:loss = 0.20464659, step = 1201 (4.252 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1291 into /var/folders/lj/b2trvfyj0mjbjf90yx92y6d80000gn/T/tmpfplgq5h5/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.09968871.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/lj/b2trvfyj0mjbjf90yx92y6d80000gn/T/tmpfplgq5h5/model.ckpt-1291\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "accuracy: 0.9284\n"
     ]
    }
   ],
   "source": [
    "Model = tf.keras.models.Model\n",
    "Input, Reshape, Dense, Conv2D = tf.keras.Input, tf.keras.layers.Reshape, tf.keras.layers.Dense, tf.keras.layers.Conv2D\n",
    "MaxPooling2D, Flatten = tf.keras.layers.MaxPooling2D, tf.keras.layers.Flatten\n",
    "\n",
    "x = x_ = Input(shape=(784, ), name='lenet_input')\n",
    "x_ = Reshape(target_shape=(28, 28, 1))(x_)\n",
    "x_ = Conv2D(6, kernel_size=(5, 5), strides=1, padding='same', activation='relu')(x_)\n",
    "x_ = MaxPooling2D(pool_size=(2, 2), strides=2)(x_)\n",
    "x_ = Conv2D(16, kernel_size=(5, 5), strides=1, activation='relu')(x_)\n",
    "x_ = MaxPooling2D(pool_size=(2, 2), strides=2)(x_)\n",
    "x_ = Flatten()(x_)\n",
    "x_ = Dense(120, activation='relu')(x_)\n",
    "x_ = Dense(84, activation='relu')(x_)\n",
    "y = x_ = Dense(10, activation='softmax', name='lenet_output')(x_)\n",
    "\n",
    "model = Model(x, y)\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metric='categorical_accuracy')\n",
    "lenet5 = tf.keras.estimator.model_to_estimator(keras_model=model)\n",
    "\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"lenet_input\": mnist.train.images}, y=mnist.train.labels, num_epochs=3, shuffle=True)\n",
    "lenet5.train(train_input_fn)\n",
    "\n",
    "validation_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"lenet_input\": mnist.validation.images}, y=mnist.validation.labels, num_epochs=1, shuffle=False)\n",
    "predictions = lenet5.predict(validation_input_fn)\n",
    "num_correct = np.sum(np.argmax(mnist.validation.labels, axis=-1) == [np.argmax(p['lenet_output']) for p in predictions])\n",
    "print('accuracy: {}'.format(num_correct / len(mnist.validation.labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
